{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a56a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data file\n",
    "with open(\"Data//names.txt\", 'r', encoding='utf-8') as myfile:\n",
    "    mytext = myfile.read()\n",
    "\n",
    "mytext = mytext.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4df6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mary\\nannie\\nanna\\nmargaret\\nhelen\\nelsie\\nlucy\\ndorothy\\nmary\\nmargaret\\nruth\\nannie\\nelizabeth\\nhelen\\nmary\\nelsi'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how the name data looks like in RAW format\n",
    "mytext[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad81ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# create a mapping of letters to integers\n",
    "letter_tokens = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':6, 'g':7, 'h':8, 'i':9, 'j':10,\n",
    "                 'k':11, 'l':12, 'm':13, 'n':14, 'o':15, 'p':16, 'q':17, 'r':18, 's':19,\n",
    "                 't':20, 'u':21, 'v':22, 'w':23, 'x':24, 'y':25, 'z':26, '<end>':27}\n",
    "\n",
    "total_letters = len(letter_tokens) + 1\n",
    "print(total_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6402b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 21, 19, 8, 11, 1, 27]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to convert a word to a sequence of integers + end token\n",
    "def word_to_sequence(word):\n",
    "    return [letter_tokens[char] for char in word if char in letter_tokens]+[27]\n",
    "\n",
    "word_to_sequence(\"anushka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input sequences and corresponding labels\n",
    "my_input_sequences = []\n",
    "for line in mytext.split('\\n'):\n",
    "    #print(line)\n",
    "    token_list = word_to_sequence(line)\n",
    "    #print(token_list)\n",
    "    for i in range(1, len(token_list)):\n",
    "        my_n_gram_sequence = token_list[:i+1]\n",
    "        #print(my_n_gram_sequence)\n",
    "        my_input_sequences.append(my_n_gram_sequence)\n",
    "        #print(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfed90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 1, 18]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example input sequences\n",
    "my_input_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686de34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences before: 6246979\n",
      "Total sequences after: 1000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total sequences before:\", len(my_input_sequences))\n",
    "\n",
    "# Shuffle and keep only a subset of sequences\n",
    "random.shuffle(my_input_sequences)\n",
    "max_samples = 1_000_000  \n",
    "my_input_sequences_rand = my_input_sequences[:max_samples]\n",
    "\n",
    "print(\"Total sequences after:\", len(my_input_sequences_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217bb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences to have the same length\n",
    "max_sequence_len = max([len(seq) for seq in my_input_sequences_rand])\n",
    "input_sequences = np.array(pad_sequences(my_input_sequences_rand, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7ec1233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of sequences: 16\n"
     ]
    }
   ],
   "source": [
    "print(f'Max length of sequences: {max_sequence_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209598eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2, 18, 25,  1],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example padded input sequences\n",
    "input_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac792405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictors and label\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88bf3968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2, 18, 25],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c844efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71baab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encode the labels\n",
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_letters))\n",
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 17:35:34.751303: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-12-28 17:35:34.751331: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-12-28 17:35:34.751337: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-12-28 17:35:34.751357: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-12-28 17:35:34.751369: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,228</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m2,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m4,228\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,628</span> (615.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m157,628\u001b[0m (615.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,628</span> (615.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m157,628\u001b[0m (615.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_letters, 100))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_letters, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.build(input_shape=(None, max_sequence_len-1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc38ae18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 17:35:43.280849: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.3634 - loss: 2.0167 - val_accuracy: 0.5528 - val_loss: 1.3838\n",
      "Epoch 2/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 43ms/step - accuracy: 0.5437 - loss: 1.3979 - val_accuracy: 0.5992 - val_loss: 1.2191\n",
      "Epoch 3/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.5762 - loss: 1.2790 - val_accuracy: 0.6103 - val_loss: 1.1654\n",
      "Epoch 4/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.5888 - loss: 1.2268 - val_accuracy: 0.6145 - val_loss: 1.1362\n",
      "Epoch 5/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 44ms/step - accuracy: 0.5954 - loss: 1.1979 - val_accuracy: 0.6212 - val_loss: 1.1154\n",
      "Epoch 6/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.6002 - loss: 1.1780 - val_accuracy: 0.6213 - val_loss: 1.1035\n",
      "Epoch 7/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.6028 - loss: 1.1622 - val_accuracy: 0.6264 - val_loss: 1.0927\n",
      "Epoch 8/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 49ms/step - accuracy: 0.6067 - loss: 1.1526 - val_accuracy: 0.6248 - val_loss: 1.0871\n",
      "Epoch 9/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 44ms/step - accuracy: 0.6086 - loss: 1.1406 - val_accuracy: 0.6273 - val_loss: 1.0807\n",
      "Epoch 10/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.6101 - loss: 1.1344 - val_accuracy: 0.6280 - val_loss: 1.0758\n",
      "Epoch 11/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6116 - loss: 1.1255 - val_accuracy: 0.6287 - val_loss: 1.0720\n",
      "Epoch 12/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 44ms/step - accuracy: 0.6115 - loss: 1.1250 - val_accuracy: 0.6302 - val_loss: 1.0680\n",
      "Epoch 13/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6140 - loss: 1.1155 - val_accuracy: 0.6310 - val_loss: 1.0639\n",
      "Epoch 14/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6132 - loss: 1.1157 - val_accuracy: 0.6301 - val_loss: 1.0636\n",
      "Epoch 15/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.6151 - loss: 1.1079 - val_accuracy: 0.6312 - val_loss: 1.0607\n",
      "Epoch 16/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6150 - loss: 1.1082 - val_accuracy: 0.6327 - val_loss: 1.0586\n",
      "Epoch 17/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 44ms/step - accuracy: 0.6151 - loss: 1.1045 - val_accuracy: 0.6301 - val_loss: 1.0579\n",
      "Epoch 18/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6161 - loss: 1.1036 - val_accuracy: 0.6314 - val_loss: 1.0555\n",
      "Epoch 19/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 45ms/step - accuracy: 0.6173 - loss: 1.0982 - val_accuracy: 0.6331 - val_loss: 1.0526\n",
      "Epoch 20/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.6174 - loss: 1.0961 - val_accuracy: 0.6301 - val_loss: 1.0522\n",
      "Epoch 21/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6181 - loss: 1.0959 - val_accuracy: 0.6303 - val_loss: 1.0526\n",
      "Epoch 22/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 45ms/step - accuracy: 0.6189 - loss: 1.0928 - val_accuracy: 0.6308 - val_loss: 1.0500\n",
      "Epoch 23/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6179 - loss: 1.0953 - val_accuracy: 0.6339 - val_loss: 1.0473\n",
      "Epoch 24/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 45ms/step - accuracy: 0.6188 - loss: 1.0901 - val_accuracy: 0.6334 - val_loss: 1.0479\n",
      "Epoch 25/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 44ms/step - accuracy: 0.6194 - loss: 1.0875 - val_accuracy: 0.6339 - val_loss: 1.0449\n",
      "Epoch 26/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.6190 - loss: 1.0876 - val_accuracy: 0.6328 - val_loss: 1.0445\n",
      "Epoch 27/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6206 - loss: 1.0844 - val_accuracy: 0.6322 - val_loss: 1.0442\n",
      "Epoch 28/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6198 - loss: 1.0860 - val_accuracy: 0.6351 - val_loss: 1.0425\n",
      "Epoch 29/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 45ms/step - accuracy: 0.6204 - loss: 1.0822 - val_accuracy: 0.6354 - val_loss: 1.0427\n",
      "Epoch 30/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6205 - loss: 1.0817 - val_accuracy: 0.6335 - val_loss: 1.0427\n",
      "Epoch 31/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6209 - loss: 1.0811 - val_accuracy: 0.6351 - val_loss: 1.0417\n",
      "Epoch 32/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 45ms/step - accuracy: 0.6210 - loss: 1.0812 - val_accuracy: 0.6360 - val_loss: 1.0403\n",
      "Epoch 33/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 45ms/step - accuracy: 0.6196 - loss: 1.0830 - val_accuracy: 0.6350 - val_loss: 1.0400\n",
      "Epoch 34/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.6209 - loss: 1.0789 - val_accuracy: 0.6345 - val_loss: 1.0403\n",
      "Epoch 35/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6209 - loss: 1.0777 - val_accuracy: 0.6365 - val_loss: 1.0383\n",
      "Epoch 36/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 45ms/step - accuracy: 0.6215 - loss: 1.0737 - val_accuracy: 0.6350 - val_loss: 1.0380\n",
      "Epoch 37/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.6219 - loss: 1.0741 - val_accuracy: 0.6347 - val_loss: 1.0392\n",
      "Epoch 38/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 45ms/step - accuracy: 0.6210 - loss: 1.0745 - val_accuracy: 0.6357 - val_loss: 1.0383\n",
      "Epoch 39/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 45ms/step - accuracy: 0.6219 - loss: 1.0753 - val_accuracy: 0.6363 - val_loss: 1.0373\n",
      "Epoch 40/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6224 - loss: 1.0740 - val_accuracy: 0.6368 - val_loss: 1.0364\n",
      "Epoch 41/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 45ms/step - accuracy: 0.6225 - loss: 1.0732 - val_accuracy: 0.6359 - val_loss: 1.0360\n",
      "Epoch 42/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 45ms/step - accuracy: 0.6211 - loss: 1.0721 - val_accuracy: 0.6364 - val_loss: 1.0360\n",
      "Epoch 43/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 45ms/step - accuracy: 0.6236 - loss: 1.0686 - val_accuracy: 0.6357 - val_loss: 1.0352\n",
      "Epoch 44/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6226 - loss: 1.0699 - val_accuracy: 0.6369 - val_loss: 1.0355\n",
      "Epoch 45/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - accuracy: 0.6220 - loss: 1.0702 - val_accuracy: 0.6359 - val_loss: 1.0344\n",
      "Epoch 46/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 44ms/step - accuracy: 0.6232 - loss: 1.0683 - val_accuracy: 0.6367 - val_loss: 1.0341\n",
      "Epoch 47/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 44ms/step - accuracy: 0.6230 - loss: 1.0688 - val_accuracy: 0.6366 - val_loss: 1.0330\n",
      "Epoch 48/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 44ms/step - accuracy: 0.6230 - loss: 1.0684 - val_accuracy: 0.6349 - val_loss: 1.0335\n",
      "Epoch 49/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 44ms/step - accuracy: 0.6229 - loss: 1.0676 - val_accuracy: 0.6378 - val_loss: 1.0318\n",
      "Epoch 50/50\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 43ms/step - accuracy: 0.6233 - loss: 1.0670 - val_accuracy: 0.6360 - val_loss: 1.0336\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(X, y, epochs=50, batch_size=256, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2816fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate names\n",
    "PAD_ID = 0\n",
    "END_ID = letter_tokens['<end>']\n",
    "index_to_char = {idx: ch for ch, idx in letter_tokens.items()}\n",
    "\n",
    "def name_generator(first_letters, min_length=4, max_length=12):\n",
    "    name = first_letters.lower()\n",
    "\n",
    "    while len(name) < max_length:\n",
    "        token_list = word_to_sequence(name)[:-1]\n",
    "\n",
    "        token_list = pad_sequences(\n",
    "            [token_list],\n",
    "            maxlen=max_sequence_len - 1,\n",
    "            padding='pre',\n",
    "            value=PAD_ID,\n",
    "        )\n",
    "\n",
    "        preds = model.predict(token_list, verbose=0)[0]\n",
    "\n",
    "        if len(name) < min_length:\n",
    "            sorted_ids = np.argsort(preds)[::-1]\n",
    "            next_id = None\n",
    "            for idx in sorted_ids:\n",
    "                if idx not in (PAD_ID, END_ID):\n",
    "                    next_id = int(idx)\n",
    "                    break\n",
    "\n",
    "            if next_id is None:\n",
    "                break\n",
    "        else:\n",
    "            next_id = int(np.argmax(preds))\n",
    "            if next_id in (PAD_ID, END_ID):\n",
    "                break\n",
    "\n",
    "        next_char = index_to_char[next_id]\n",
    "        name += next_char\n",
    "\n",
    "    return name.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4732684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skylar'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_generator('Sk', min_length=5, max_length=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a444163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: baby_name_lstm_v1.keras\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "MODEL_PATH = \"baby_name_lstm_v1.keras\"\n",
    "\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Model saved to:\", MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tfMAC310)",
   "language": "python",
   "name": "tfmac310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
